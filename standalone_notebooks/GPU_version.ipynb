{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: CPU and GPU match within tolerance 1e-06.\n",
      "Max difference in X: 1.1920928955078125e-07, in t: 0.0\n",
      "==> Running drift-implicit on CPU...\n",
      "CPU time: 123.8162 s\n",
      "==> Running drift-implicit on GPU...\n",
      "GPU time: 19.6495 s\n",
      "==> Running Explicit Euler–Maruyama on CPU...\n",
      "CPU time: 30.2360 s\n",
      "==> Running Explicit Euler–Maruyama on GPU...\n",
      "GPU time: 2.9217 s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "##############################################################################\n",
    "# A) UNIVERSAL CONSTANTS\n",
    "##############################################################################\n",
    "PERIOD      = 100.0\n",
    "A2          = -3.2\n",
    "SIN_SCALE   = 3.0\n",
    "A4          = 0.1\n",
    "A6          = 1.0\n",
    "ALL_SCALE   = 1.0 \n",
    "\n",
    "def a3_func(t):\n",
    "    return SIN_SCALE * torch.sin(2.0 * torch.pi * t / PERIOD)\n",
    "\n",
    "def a5_func(t):\n",
    "    return -(3.0/5.0) * a3_func(t)\n",
    "\n",
    "##############################################################################\n",
    "# B) DERIVATIVES OF THE POTENTIAL\n",
    "##############################################################################\n",
    "\n",
    "def d_poly__d_x_torch(x, t):\n",
    "    a3_val = a3_func(t)\n",
    "    a5_val = a5_func(t)\n",
    "\n",
    "    return ALL_SCALE * (\n",
    "         A6*6.0*x**5\n",
    "       + a5_val*5.0*x**4\n",
    "       + A4*4.0*x**3\n",
    "       + a3_val*3.0*x**2\n",
    "       + A2*2.0*x\n",
    "    )\n",
    "\n",
    "def d2_poly__d_x2_torch(x, t):\n",
    "    a3_val = a3_func(t)\n",
    "    a5_val = a5_func(t)\n",
    "\n",
    "    return ALL_SCALE * (\n",
    "         A6*30.0*x**4\n",
    "       + a5_val*20.0*x**3\n",
    "       + A4*12.0*x**2\n",
    "       + a3_val*6.0*x\n",
    "       + A2*2.0\n",
    "    )\n",
    "\n",
    "##############################################################################\n",
    "# C) DRIFT-IMPLICIT UPDATE\n",
    "##############################################################################\n",
    "\n",
    "def drift_implicit_update_torch(x_n, t_n, dt, sqrt_epsilon, dW_n,\n",
    "                                max_iter=20, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Implicit eqn: X_{n+1} + dt*U'(X_{n+1}, t_{n+1}) = x_n + sqrt_epsilon*dW_n.\n",
    "    We solve via Newton's method with derivative 1 + dt*U''(x,t_{n+1}).\n",
    "    \"\"\"\n",
    "    t_next = t_n + dt\n",
    "    A_n = x_n + sqrt_epsilon*dW_n  \n",
    "\n",
    "    # Initial guess: explicit Euler step\n",
    "    x_new = x_n - dt*d_poly__d_x_torch(x_n, t_n) + sqrt_epsilon*dW_n\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        f_val = x_new + dt*d_poly__d_x_torch(x_new, t_next) - A_n\n",
    "        df_val = 1.0 + dt*d2_poly__d_x2_torch(x_new, t_next)\n",
    "\n",
    "        # Clamp derivative to prevent blow-ups\n",
    "        df_val = torch.clamp(df_val, min=1e-14, max=1e14)\n",
    "        step = f_val / df_val\n",
    "        x_new_next = x_new - step\n",
    "\n",
    "        if torch.max(torch.abs(step)) < tol:\n",
    "            x_new = x_new_next\n",
    "            break\n",
    "\n",
    "        x_new = x_new_next\n",
    "\n",
    "    return x_new, t_next\n",
    "\n",
    "##############################################################################\n",
    "# D) EXPLICIT EULER-MARUYAMA UPDATE\n",
    "##############################################################################\n",
    "\n",
    "def euler_maruyama_update_torch(x_n, t_n, dt, sqrt_epsilon, dW_n):\n",
    "    \"\"\"\n",
    "    Explicit Euler–Maruyama step:\n",
    "        dX_t = - U'(X_t, t) dt + sqrt(eps)*dW_t\n",
    "    =>  X_{n+1} = X_n - dt*U'(X_n, t_n) + sqrt(eps)*dW_n\n",
    "    \"\"\"\n",
    "    drift_val = - d_poly__d_x_torch(x_n, t_n)\n",
    "    x_next = x_n + drift_val * dt + sqrt_epsilon * dW_n\n",
    "    t_next = t_n + dt\n",
    "    return x_next, t_next\n",
    "\n",
    "##############################################################################\n",
    "# E) EXAMPLE FUNCTION: SIMULATE SDE (DRIFT-IMPLICIT) WITH SHARED NOISE\n",
    "##############################################################################\n",
    "\n",
    "def simulate_sde_same_noise(X0, t0, dt, N, eps,\n",
    "                            device='cpu', seed=1234):\n",
    "    \"\"\"\n",
    "    Each time step uses one scalar noise for *all* trajectories.\n",
    "    CPU vs GPU will share the same increments if we fix the seed.\n",
    "    \"\"\"\n",
    "    X0 = X0.to(device)\n",
    "    batch_size = X0.shape[0]\n",
    "\n",
    "    X_all = torch.zeros(N+1, batch_size, device=device)\n",
    "    t_all = torch.zeros(N+1, device=device)\n",
    "    X_all[0] = X0\n",
    "    t_all[0] = t0\n",
    "\n",
    "    sqrt_epsilon = torch.sqrt(torch.tensor(eps, device=device))\n",
    "\n",
    "    # Pre-generate random increments on CPU for cross-device consistency\n",
    "    gen = torch.Generator(device='cpu').manual_seed(seed)\n",
    "    dWs_cpu = torch.randn(N, generator=gen)*np.sqrt(dt)\n",
    "\n",
    "    # Copy to device if needed\n",
    "    dWs = dWs_cpu if device == 'cpu' else dWs_cpu.to(device)\n",
    "\n",
    "    for n in range(N):\n",
    "        x_n = X_all[n]\n",
    "        t_n = t_all[n].expand_as(x_n)\n",
    "\n",
    "        # Single scalar => expand to entire batch\n",
    "        dW_n = dWs[n].expand(batch_size)\n",
    "\n",
    "        # >>> DRIFT-IMPLICIT STEP:\n",
    "        x_new, t_new = drift_implicit_update_torch(\n",
    "            x_n, t_n, dt, sqrt_epsilon, dW_n\n",
    "        )\n",
    "\n",
    "        X_all[n+1] = x_new\n",
    "        t_all[n+1] = t_all[n] + dt\n",
    "\n",
    "    return X_all, t_all\n",
    "\n",
    "def simulate_sde_euler_explicit_same_noise(\n",
    "    X0, t0, dt, N, eps, device='cpu', seed=1234\n",
    "):\n",
    "    X0 = X0.to(device)\n",
    "    batch_size = X0.shape[0]\n",
    "    X_all = torch.zeros(N+1, batch_size, device=device)\n",
    "    t_all = torch.zeros(N+1, device=device)\n",
    "\n",
    "    X_all[0] = X0\n",
    "    t_all[0] = t0\n",
    "\n",
    "    sqrt_epsilon = torch.sqrt(torch.tensor(eps, device=device))\n",
    "\n",
    "    # Pre-generate random increments on CPU for cross-device consistency\n",
    "    gen = torch.Generator(device='cpu').manual_seed(seed)\n",
    "    dWs_cpu = torch.randn(N, generator=gen)*np.sqrt(dt)\n",
    "\n",
    "    # Copy to device if needed\n",
    "    dWs = dWs_cpu if device=='cpu' else dWs_cpu.to(device)\n",
    "\n",
    "    for n in range(N):\n",
    "        x_n = X_all[n]\n",
    "        t_n = t_all[n].expand_as(x_n)\n",
    "\n",
    "        dW_n = dWs[n].expand(batch_size)  # share same increment\n",
    "        x_next, t_next = euler_maruyama_update_torch(x_n, t_n, dt, sqrt_epsilon, dW_n)\n",
    "\n",
    "        X_all[n+1] = x_next\n",
    "        t_all[n+1] = t_all[n] + dt\n",
    "\n",
    "    return X_all, t_all\n",
    "\n",
    "##############################################################################\n",
    "# F) TIMING\n",
    "##############################################################################\n",
    "\n",
    "def time_cpu_vs_gpu():\n",
    "    # Example usage for timing\n",
    "    batch_size = 500000\n",
    "    N = 1000\n",
    "    dt = 0.01\n",
    "    eps = 0.1\n",
    "    t0 = 0.0\n",
    "\n",
    "    # CPU\n",
    "    X0_cpu = torch.zeros(batch_size, dtype=torch.float32)\n",
    "    print(\"==> Running drift-implicit on CPU...\")\n",
    "    start_cpu = time.time()\n",
    "    X_cpu, t_cpu = simulate_sde_same_noise(\n",
    "        X0_cpu, t0, dt, N, eps, device='cpu', seed=1234\n",
    "    )\n",
    "    cpu_time = time.time() - start_cpu\n",
    "    print(f\"CPU time: {cpu_time:.4f} s\")\n",
    "\n",
    "    # GPU (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"==> Running drift-implicit on GPU...\")\n",
    "        X0_gpu = X0_cpu.clone()  # same initial state\n",
    "        start_gpu = time.time()\n",
    "        X_gpu, t_gpu = simulate_sde_same_noise(\n",
    "            X0_gpu, t0, dt, N, eps, device='cuda', seed=1234\n",
    "        )\n",
    "        torch.cuda.synchronize()\n",
    "        gpu_time = time.time() - start_gpu\n",
    "        print(f\"GPU time: {gpu_time:.4f} s\")\n",
    "    else:\n",
    "        print(\"No CUDA device found; skipping GPU test.\")\n",
    "\n",
    "def time_cpu_vs_gpu_euler_explicit():\n",
    "    # Problem size\n",
    "    batch_size = 1000000\n",
    "    N = 1000\n",
    "    dt = 0.01\n",
    "    eps = 0.1\n",
    "    t0 = 0.0\n",
    "\n",
    "    # All initial states zero\n",
    "    X0_cpu = torch.zeros(batch_size, dtype=torch.float32)\n",
    "\n",
    "    print(\"==> Running Explicit Euler–Maruyama on CPU...\")\n",
    "    start_cpu = time.time()\n",
    "    X_cpu, t_cpu = simulate_sde_euler_explicit_same_noise(\n",
    "        X0=X0_cpu, t0=t0, dt=dt, N=N, eps=eps, device='cpu', seed=1234\n",
    "    )\n",
    "    end_cpu = time.time()\n",
    "    cpu_time = end_cpu - start_cpu\n",
    "    print(f\"CPU time: {cpu_time:.4f} s\")\n",
    "\n",
    "    # GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"==> Running Explicit Euler–Maruyama on GPU...\")\n",
    "        X0_gpu = X0_cpu.clone()\n",
    "        start_gpu = time.time()\n",
    "        X_gpu, t_gpu = simulate_sde_euler_explicit_same_noise(\n",
    "            X0=X0_gpu, t0=t0, dt=dt, N=N, eps=eps, device='cuda', seed=1234\n",
    "        )\n",
    "        torch.cuda.synchronize()  # ensure completion\n",
    "        end_gpu = time.time()\n",
    "        gpu_time = end_gpu - start_gpu\n",
    "        print(f\"GPU time: {gpu_time:.4f} s\")\n",
    "    else:\n",
    "        print(\"No CUDA device found. Skipping GPU test.\")\n",
    "\n",
    "##############################################################################\n",
    "# G) Check CPU == GPU\n",
    "##############################################################################\n",
    "\n",
    "def check_cpu_vs_gpu_match():\n",
    "    # Parameters\n",
    "    batch_size = 10    \n",
    "    N = 1000            \n",
    "    dt = 0.01\n",
    "    eps = 0.5\n",
    "    t0 = 0.0\n",
    "\n",
    "    # CPU version\n",
    "    X0_cpu = torch.zeros(batch_size, dtype=torch.float32)\n",
    "    X_cpu, t_cpu = simulate_sde_same_noise(\n",
    "        X0_cpu, t0, dt, N, eps, device='cpu', seed=1234\n",
    "    )\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"No CUDA device found; skipping GPU check.\")\n",
    "        return\n",
    "\n",
    "    # GPU version\n",
    "    X0_gpu = X0_cpu.clone()  # same initial condition\n",
    "    X_gpu, t_gpu = simulate_sde_same_noise(\n",
    "        X0_gpu, t0, dt, N, eps, device='cuda', seed=1234\n",
    "    )\n",
    "\n",
    "    # Bring GPU results to CPU for comparison\n",
    "    X_gpu_cpu = X_gpu.cpu()\n",
    "    t_gpu_cpu = t_gpu.cpu()\n",
    "\n",
    "    # Compare shapes\n",
    "    if X_cpu.shape != X_gpu_cpu.shape or t_cpu.shape != t_gpu_cpu.shape:\n",
    "        print(\"ERROR: CPU and GPU shapes differ!\")\n",
    "        return\n",
    "\n",
    "    # Compare numerical values\n",
    "    diff_X = torch.abs(X_cpu - X_gpu_cpu).max().item()\n",
    "    diff_t = torch.abs(t_cpu - t_gpu_cpu).max().item()\n",
    "\n",
    "    tol = 1e-6  # example tolerance\n",
    "    if diff_X < tol and diff_t < tol:\n",
    "        print(f\"SUCCESS: CPU and GPU match within tolerance {tol}.\")\n",
    "        print(f\"Max difference in X: {diff_X}, in t: {diff_t}\")\n",
    "    else:\n",
    "        print(\"WARNING: CPU and GPU differ.\")\n",
    "        print(f\"Max diff in X: {diff_X}, in t: {diff_t}\")\n",
    "        print(f\"(You can raise tolerance if small floating errors are okay.)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_cpu_vs_gpu_match()\n",
    "    time_cpu_vs_gpu()\n",
    "    time_cpu_vs_gpu_euler_explicit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
